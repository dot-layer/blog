---
title: "Boosting Trees avec Julia"
author: "Jeremie"
date: "2019-01-04"
slug: "julia-boosting-trees"
type: "post"
tags: ["Machine Learning", "Julia"]
description: "description"
---


```{r setup, include=FALSE}
library(magrittr)
library(data.table)
library(plotly)
library(ggplot2)
library(knitr)
library(kableExtra)
library(extrafont)
library(scales)
# library(EvoTrees)
```


> Cet article a pour but d'exposer les principes cl√©s permettant une implantation haute performance du gradient boosting trees en Julia, permettant de b√©n√©ficier √† la fois de l'expressivit√© d'un language dynamique comme Python ou R et de la performance d'un langage compil√© le C/C++. 

Bien que les approches par r√©seaux de neuronnes accaparent une bonne partie de l'attention, l'importances des algorithmes reposant sur des artbres de d√©cision ne peut √™tre n√©glig√©e. Ils continuent de se d√©marquer comme offrant la meilleure performance pr√©dictive dans de nombreuses situations, particuli√®rement lorsqu'il s'agit de probl√®mes de r√©gresion ou de classification impliquant des donn√©es tabulaires.

Parmi les plus c√©l√®bres repr√©sentants de cette famille d'algorithmes, on compte [Xgboost](https://xgboost.readthedocs.io/en/latest/), [LightGBM](https://lightgbm.readthedocs.io/en/latest/) et [CatBoost](). Si ces derni√®res implantations sont relativement r√©centes (2014, 2016 et 2017), l'algorithme avait √©t√© d√©velopp√© depuis d√©j√† quelques ann√©es, puisqu'on le retrouve d√®s 2001 dans le d√©sormais classique [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/). 

Il serait hasardeux d'apporter un diagnostic d√©finitif sur ce qui a conduit √† l'explosion de popularit√© de l'algorithme. L'int√©r√™t pour pour le l'apprentissage machine et le d√©veloppement d'une approche comp√©titive √† la mod√©lisation via des plateformes comme Kaggle n'y sont sans doute pas √©trangers. Un atout du gradient boosting est √©galement sa rapidit√©: Xgboost apportait √† sa sortie une r√©duction du temps d'entra√Ænement de l'ordre de 10X par rapports au implantations R et Python existantes. 

Dans un contexte d'utilisation commerciale, les enjeux de performance deviennent rapidement significatifs compte tenu des volumes de donn√©es impliqu√©s. Le soucis qu'on y accorde au sein de la nouvelle g√©n√©ration d'algorithmes y est sans doute li√©. Aussi, lorsqu'il est question de performance, le coeur de l'algorithme est typiquement d√©velopp√© dans un lnagage compil√© tel le le C/C++, bien que l'utilisateur interagit le plus souvent au travers de langages dynamiques comme Python et R et facilient l'interface avec le code source.  

Dans ce contexte, une des facettes int√©ressante du langage Julia qui se veut une r√©ponse √† l'enjeu des 2 langages. Les figure ci-dessous montrent que l'int√©gralit√© de l'implantation Julia du gradient boosting est cod√©e... en Julia! 

![](xgboost_github.PNG)

La suite de l'article a pour but de montrer comment il est possible d'implanter des algorithmes "from scratch" dans un langage convivial tout en obtenant des vitesses d'ex√©cution comp√©titives aux solutions les plus performantes sur le marhc√©. 


## Mise en contexte

Afin de rendre plus tangible les d√©tails de l'implantation du gradient boosting en Julia, un probl√®me de r√©gression avec 2 variables continues est pr√©sent√©. 

La variable r√©ponse est d√©pendante des variables var1 et var2. L'effet est sinuso√Ødal en `var1` et croissant en `var2`.

![](data_3D.png)

![](raw_one_ways.png)


## Introduction √† l'algorithme

L'entra√Ænement d'un gradient boosting trees peut √™tre d√©crit sommairement de la mani√®re suivante: 

0. D√©finir une pr√©diction de base pour chacune des observations. Ex: pred = 0.0
1. Construire un arbre de d√©cision, _A1_ expliquant la diff√©rence entre les pr√©dicitons et les valeurs observ√©es.  
2. Mettre √† jour les pr√©dicions en ajoutant les pr√©dictions de l'arbre _A1_ aux pr√©dictions actuelles: pred = pred + predict(_A1_)
3. R√©p√©ter 1. et 2. pour un nombre N arbres.

Dans un sc√©nario o√π le nombre d'it√©rtions est 4, le mod√®le entra√Æn√© pourrait se visualiser de la fa√ßon suivante: 

![](tree_group.png)

Pour obtenir une pr√©diction, il suffit d'additionner la pr√©diction obtenue √† chacun des 4 arbres. 

Comme on peut le constater, un mod√®le GBT ne consiste qu'en une collection d'arbres de d√©cision. Quelques subtilit√©s sont n√©anmoins introduites en pratique, par exemple le r√©chantillonnage des observations et des variables explicatives √† chacune des it√©rations. Reste qu'une fois qu'on a √©tablit comment construire un arbre de d√©cision, l'essentiel du travail est accompli. √Ä noter que la m√™me logique s'appliquerait si on construisait un RandomForest: il ne suffirait encore l√† que de savoir construire un arbre de d√©cision, le reste n'est qu'une variation de l'algorithme pr√©sent√© plus haut. 

En julia, on peut d√©finir la structure du mod√®le de la mani√®re suivante, o√π un GBTree est compos√©e d'une vecteur de Tree: 

```julia
struct GBTree
    trees::Vector{Tree}
    params
    metric
end
```

En son coeur Julia supporte des repr√©sentations multi-dimensionnelles via des Array{T,N}. Un vector `Vector{T}` ou une matrice `Matrix{T}` ne sont que des cas particulies des Array{T,N}, o√π N = 1 et 2 respectivement. L'√©l√©ment `T` dans Array{T,N} r√©f√®re au type. Lorsqu'on travaille avec un vecteur de nombres continus, par exemple en R avec `c(1.1, 2.2)` ou en Python avec [1.1, 2.2], on se trouverait dans l'univers Julia √† travailler avec un Vector{Float64} (ou encore Float32/Float16 au besoin). En Julia, cette repr√©sentation multidimensionnelle ne se limite pas aux nombres conventionnels comme les Float ou les Integer, √ßa peut √™tre n'importe quel type d'object. Par exmeple, on pourrait parfaitement avoir une matrice dont les √©l√©ments sont des DataFrames (mais le produit matriciel de tels objects resterait √† d√©finir!). Dans le cas pr√©sent, le choix est pris de d√©finir un mod√®le de GBTree comme constitu√© d'une vecteur d'arbres. 

## D√©finition d'un arbre

Tel que montr√© plus haut, un arbre de d√©cision se compose d'une s√©rie de noeuds comportant chacun une d√©cision binaire. Par exemple, dans l'arbre ci-dessous, on commence par d√©cider, pour chaque observation, si la variable 1 est plus petite que X. Si on va dans le segment de gauche, la d√©cision suivante est si la variable 2 est plus petite que `X`. On arrive ensuite √† un noeud terminal qui indique la pr√©diction √† associer √† l'observation. 

![](tree_1.png)

Une structure r√©cursive peut √™tre une repr√©sentation intuitve pour un arbre. On d√©finit alors comme objet un noeud qui contient le crit√®re de d√©cision ainsi que 2 noeuds d√©pendants ("child nodes") selon que la condition soit respect√©e ou non. Il est √©galement possible de repr√©senter un arbre par un simple vecteur de noeuds: 

```julia
struct Tree{L, T<:AbstractFloat, S<:Int}
    nodes::Vector{TreeNode}
end
```

```julia
struct TreeNode{L, T<:AbstractFloat, S<:Int, B<:Bool}
    left::S
    right::S
    feat::S
    cond::T
    pred::SVector{L,T}
    split::B
end
```

Comme on peut le voir dans le TreeNode, pour chaque noeud on doit d√©finir sur quelle variable la d√©cision doit √™tre prise ainsi que la condition √† appliquer. 

Une fois les structures en place, ne reste plus qu'√† identifier les valeurs que doivent prendre ces structures.

## Construction d'un arbre

Il s'agit d'√©valuer pour chaque variable la condition apportant le plus grande r√©duction de la fonction de perte. C'est l√† que l'essentiel de la charge de calcul se trouve et que certains choix de design permettront d'atteindre des performances optimales. Ensuite, la variable dont la condition optimale apporte le plus grand gain sera retenu pour d√©finir la condition pour le noeud. 

Pour chaque noeud, l'algorithme s'exerce d'une perspective univari√©e. La capacit√© d'un arbre √† r√©fl√©ter des int√©ractions entre variables provient du fait que les conditions dans les sous-branches s'exercent de fa√ßon ind√©pendante. On a l√† un premier √©l√©ment se pr√™tant √† une optimisation: puisque l'√©valuation de la meilleure condition se fait de fa√ßon ind√©pendante pour chaque variable, il s'agit d'une recherche qui se parall√©lise ais√©ment. 

Julia supporte plusieurs saveurs de parall√©lisme. Dans le cas de la recherche de variables, tous les coeurs du processeur peuvent √™tre mis √† profit simplement en utilisant la macro `@threads`. 

```julia
@threads for j in cols
  find_best_split!()
end
```

Une fa√ßon brute de chercher le meilleur bris est de de mettre en ordre les observations selon une variable donn√©e. Une fois les observations en ordre, on peut consid√©rer pour chacune des valeurs uniques prises par cette variable quel serait le gain si la condition s'exer√ßait sur cette valeur. 

Une telle approche fonctionne, mais est sujette √† quelques inconvnients. D'abord, ordonner une variable est une op√©ration couteuse, particuli√®rement si on consid√®re que l'op√©ration doit √™tre r√©p√©t√©e pour plusieurs variables, pour chacun des noeuds et pour chaque arbre. √âgalement, si le nombre de valeurs uniques prises par une variable est tr√®s √©lev√©e, √ßa implique d'√©valuer le gain √† un tr√®s grand nombre de reprises. 

La m√©thode de l'histogramme permet de contourner ces obstacles. L'id√©e de discr√©tiser chaque variable en associant chaque observation √† un groupe, bas√© par exemple sur le quantile. En utilisant un entier entre 0 et 255 comme identifiant de ces groupes, la matrice de donn√©es est encod√©e dans un format UInt8, lequel accapare 8 fois moins de m√©moire qu'un format Float64 (un _numeric_ en R). 

Avant la construction des arbres, la librairie EvoTrees effectue cette discr√©tisation en trouvant d'abord les quantiles pour chacune des variables (get_edges), puis en cr√©ant une matrice de `UInt8`.

```julia
edges = EvoTrees.get_edges(X_train, params.nbins)
X_bin = EvoTrees.binarize(X_train, edges)
```

En choisissant le nombre de groupe (nbins) comme √©tant 16, le probl√®me √† r√©soudre prend la forme suivante d'un point de vue univari√©.

![](bin_one_ways.png)

Sous cette formulation, le nombre de conditions √† √©valuer se limite d√©sormais √† 15 (ou plus g√©n√©ralement, nbins-1). 

Il reste enfin √† d√©finir le gain associ√© √† chacun des bris. Une force du gradient boosting est sa flexibilit√©. Sous l'implantation introduite par Xgboost, il suffit de d√©finir une fonction de perte qui soit convexe et donc que la d√©riv√©e seconde existe et soit positive en tout point. Pour l'illustrer, on peut prendre le cas d'une r√©gression classique. 

Avec une r√©gression des moindre carr√©s, la perte est d√©finie par $(y - pred)^2$. Cette perte a une forme parabolique et son minimum est bien entendu lorsque la valeur pr√©dite √©gale la valeur observ√©e. La notion critique √† remarquer est qu'en ne connaissant que les d√©riv√©es premi√®res et secondes de la perte par rapport √† la pr√©diction, il est possible de d√©terminer non seulement quel serait la pr√©diction optimale, mais √©galement la r√©duction de la perte. 

Pouor le premier des 15 conditions possibles, l'arbre distinguerait les donn√©es en les groupes gauche et droite de la mani√®re suivante:  

![](first_split.png)

Le gain apport√© est calcul√© comme la r√©duction de la perte qu'apporterait cette d√©cision. Pour y arriver, on calcule d'abord la perte sur l'ensemble des donn√©es. Effectuer un bris dans l'arbre devra apporter un gain par rapport √† cette valeur de r√©f√©rence. 

Ensuite, le gain est calcul√© s√©par√©ment pour les groupes de gauche et de droite. La perte associ√©e √† diff√©rentes pr√©dictions pour le groupe de gauche est la suivante:

![](left_parabole.png)

Il est √† noter que la perte minimale est atteinte lorsque la pr√©dictions est de -1.11, ce qui correspond √† la moyenne des r√©sidus pour le groupe 1. 

Puisqu'une approximation de 2e degr√© (d√©riv√©es premi√®re et seconde) est utilis√©e pour repr√©senter la perte, il existe une solution analytique permettant d'obtenir la valeur de la pr√©diction optimale et de la r√©duction de la perte associ√©e √† cette derni√®re. √áa revient √† trouver le minimum d'une fonction parabolique, soit la valeur de la pr√©diction o√π la d√©riv√©e premi√®re de la perte est √©gale √† 0. La d√©riv√©e de la fonction de perte √©tant lin√©aire, l'approche par descente du gradient donne une solution exacte. 

$gain = (Œ¥) ^ 2 / (‚àëŒ¥¬≤ + Œª * ‚àëùë§)/2$

$pred = - Œ∑ * ‚àëŒ¥ / (‚àëŒ¥¬≤ + Œª * ‚àëùë§)$


