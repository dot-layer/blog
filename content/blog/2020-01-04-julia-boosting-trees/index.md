---
title: "Boosting Trees avec Julia"
author: "Jeremie Desgagne-Bouchard"
date: "2020-02-04"
slug: "julia-boosting-trees"
type: "post"
tags: ["Machine Learning", "Julia"]
featured: "julia-plot.png"
featuredpath: "img/headers/"
description: "D√©veloppement d'algorithmes from scratch"
---


> Cet article a pour but d'exposer les principes cl√©s permettant une implantation haute performance du gradient boosting trees en Julia, un langage r√©conciliant l'expressivit√© et la productivit√© qu'on retrouve en Python et en R et la performance de langages compil√©s comme le C et C++. 

Bien que les approches par r√©seaux de neuronnes accaparent une bonne partie de l'attention, l'importance des algorithmes reposant sur des artbres de d√©cision ne peut √™tre n√©glig√©e. Ils continuent de se d√©marquer comme offrant la meilleure performance pr√©dictive dans de nombreuses situations, particuli√®rement lorsqu'il s'agit de probl√®mes de r√©gresion ou de classification impliquant des donn√©es tabulaires.

Parmi les plus c√©l√®bres repr√©sentants de cette famille d'algorithmes, on compte [XGBoost](https://xgboost.readthedocs.io/en/latest/), [LightGBM](https://lightgbm.readthedocs.io/en/latest/) et [CatBoost](https://catboost.ai/). Si ces derni√®res implantations sont relativement r√©centes (2014, 2016 et 2017), l'algorithme avait √©t√© d√©velopp√© depuis d√©j√† quelques ann√©es, puisqu'on le retrouve d√®s 2001 dans le d√©sormais classique [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/). 

Il serait hasardeux d'apporter un diagnostic d√©finitif sur ce qui a conduit √† l'explosion de popularit√© de l'algorithme. L'int√©r√™t pour pour l'apprentissage machine et le d√©veloppement d'une approche comp√©titive √† la mod√©lisation via des plateformes comme Kaggle n'y sont sans doute pas √©trangers. Un atout du gradient boosting est √©galement sa rapidit√©: XGBoost apportait √† sa sortie une r√©duction du temps d'entra√Ænement de l'ordre de 10X par rapport aux implantations en R et en Python existantes. 

Dans un contexte d'utilisation commerciale, les enjeux de performance deviennent rapidement significatifs compte tenu des volumes de donn√©es impliqu√©s. Le souci qu'on y accorde au sein de la nouvelle g√©n√©ration d'algorithmes y est sans doute li√©. Aussi, lorsqu'il est question de performance, le coeur de l'algorithme est typiquement d√©velopp√© dans un langage compil√© (C/C++), bien que l'utilisateur interagit le plus souvent avec ces librairies au travers d'interfaces en Python et R qui facilitent le d√©veloppement exp√©rimental.  

Une facette int√©ressante du langage Julia est qu'elle permet de briser cette barri√®re des 2 langages. La figure ci-dessous montre que l'int√©gralit√© de l'implantation Julia du gradient boosting est cod√©e... en Julia! 

![](xgboost_github.PNG)

![](julia_github.PNG)

On verra maintenant plus en d√©tails comment il est possible d'implanter des algorithmes "from scratch" dans un langage convivial tout en obtenant des vitesses d'ex√©cution comp√©titives aux solutions les plus performantes sur le march√©. 

## Mise en contexte

Afin de rendre plus tangible les d√©tails de l'implantation du gradient boosting en Julia, un probl√®me de r√©gression avec 2 variables continues servira d'exemple. 

La variable r√©ponse est d√©pendante des variables `var1` et `var2`. L'effet est sinuso√Ødal en `var1` et croissant en `var2`.

![](data_3D.png)

![](raw_one_ways.png)


## Introduction √† l'algorithme

L'entra√Ænement d'un gradient boosting trees peut √™tre d√©crit sommairement de la mani√®re suivante: 

0. D√©finir une pr√©diction de base pour chacune des observations. Ex: pred = 0.0
1. Construire un arbre de d√©cision, _A1_ expliquant la diff√©rence entre les pr√©dicitons et les valeurs observ√©es.  
2. Mettre √† jour les pr√©dicions en ajoutant les pr√©dictions de l'arbre _A1_ aux pr√©dictions actuelles: pred = pred + predict(_A1_)
3. R√©p√©ter 1. et 2. pour un nombre N arbres.

Dans un sc√©nario o√π le nombre d'it√©rations serait de 4, le mod√®le entra√Æn√© pourrait se visualiser de la fa√ßon suivante: 

![](tree_group.png)

Pour obtenir une pr√©diction, il suffit d'additionner la pr√©diction obtenue √† chacun des 4 arbres. 

Comme on peut le constater, un mod√®le GBT ne consiste qu'en une collection d'arbres de d√©cision. Quelques subtilit√©s sont n√©anmoins introduites en pratique, par exemple le r√©√©chantillonnage des observations et des variables explicatives √† chacune des it√©rations. Reste qu'une fois qu'on a √©tabli comment construire un arbre de d√©cision, l'essentiel du travail est accompli. √Ä noter que la m√™me logique s'appliquerait si on construisait un RandomForest: il ne suffirait encore l√† que de savoir construire un arbre de d√©cision, le reste n'est qu'une variation de l'algorithme pr√©sent√© plus haut. 

En Julia, on peut d√©finir la structure du mod√®le de la mani√®re suivante, o√π un GBTree est compos√© d'un vecteur de Tree: 

```julia
struct GBTree
    trees::Vector{Tree}
    params
    metric
end
```

En son coeur Julia supporte des repr√©sentations multi-dimensionnelles via des Array{T,N}. Un vector `Vector{T}` ou une matrice `Matrix{T}` ne sont que des cas particuliers des `Array{T,N}`, o√π N = 1 et 2 respectivement. L'√©l√©ment `T` dans `Array{T,N}` r√©f√®re au type. Lorsqu'on travaille avec un vecteur de nombres continus, par exemple en R avec `c(1.1, 2.2)` ou en Python avec `[1.1, 2.2]`, l'√©quivalent dans l'univers Julia serait `Vector{Float64}`: `[1.1, 2.2]` (ou encore Float32/Float16 au besoin). En Julia, cette repr√©sentation multidimensionnelle ne se limite pas aux nombres conventionnels comme les Float ou les Integer, √ßa peut √™tre n'importe quel type d'object. Par exemple, on pourrait parfaitement avoir une matrice dont les √©l√©ments sont des DataFrames (mais le produit matriciel de tels objects resterait √† d√©finir!). Dans le cas pr√©sent, le choix est pris de d√©finir un mod√®le de GBTree comme constitu√© d'une vecteur d'arbres. 

## D√©finition d'un arbre

Tel que montr√© plus haut, un arbre de d√©cision se compose d'une s√©rie de noeuds comportant chacun une d√©cision binaire. Par exemple, dans l'arbre ci-dessous, on commance par √©tablir, pour chaque observation, si la variable 1 est plus petite que `X`. Si oui, on va dans le segment de gauche et la d√©cision suivante est si la variable 2 est plus petite que `X`. On arrive ensuite √† un noeud terminal qui indique la pr√©diction √† associer √† l'observation. 

![](tree_1.png)

Une structure r√©cursive peut √™tre une repr√©sentation intuitve pour un arbre. On d√©finit alors comme objet un noeud qui contient le crit√®re de d√©cision ainsi que 2 noeuds d√©pendants ("child nodes") selon que la condition soit respect√©e ou non. Il est √©galement possible de repr√©senter un arbre par un simple vecteur de noeuds: 

```julia
struct Tree{L, T<:AbstractFloat, S<:Int}
    nodes::Vector{TreeNode}
end
```

```julia
struct TreeNode{L, T<:AbstractFloat, S<:Int, B<:Bool}
    left::S
    right::S
    feat::S
    cond::T
    pred::SVector{L,T}
    split::B
end
```

Comme on peut le voir dans le TreeNode, pour chaque noeud on doit d√©finir sur quelle variable la d√©cision doit √™tre prise ainsi que la condition √† appliquer. 

Une fois les structures en place, il ne reste plus qu'√† identifier les valeurs que doivent prendre ces structures.

## Construction d'un arbre

Il s'agit d'√©valuer pour chaque variable la condition apportant le plus grande r√©duction de la fonction de perte. C'est l√† que l'essentiel de la charge de calcul se trouve et que certains choix de design permettront d'atteindre des performances optimales. Ensuite, la variable dont la condition optimale apporte le plus grand gain sera retenu pour d√©finir la condition pour le noeud. 

Pour chaque noeud, l'algorithme s'exerce d'une perspective univari√©e. La capacit√© d'un arbre √† r√©fl√©ter des int√©ractions entre variables provient du fait que les conditions dans les sous-branches s'exercent de fa√ßon ind√©pendante. On a l√† un premier √©l√©ment se pr√™tant √† une optimisation: puisque l'√©valuation de la meilleure condition se fait de fa√ßon ind√©pendante pour chaque variable, il s'agit d'une recherche qui se parall√©lise ais√©ment. 

Julia supporte plusieurs saveurs de parall√©lisme. Dans le cas de la recherche de variables, tous les coeurs du processeur peuvent √™tre mis √† profit simplement en utilisant la macro `@threads`. 

```julia
@threads for j in cols
  find_best_split!()
end
```

Une fa√ßon brute de chercher le meilleur bris est de de mettre en ordre les observations selon une variable donn√©e. Une fois les observations en ordre, on peut consid√©rer pour chacune des valeurs uniques prises par cette variable quel serait le gain si la condition s'exer√ßait sur cette valeur. 

Une telle approche fonctionne, mais est sujette √† quelques inconv√©nients. D'abord, ordonner une variable est une op√©ration co√ªteuse, particuli√®rement si on consid√®re que l'op√©ration doit √™tre r√©p√©t√©e pour plusieurs variables, pour chacun des noeuds et pour chaque arbre. √âgalement, si le nombre de valeurs uniques prises par une variable est tr√®s √©lev√©e, √ßa implique d'√©valuer le gain √† un tr√®s grand nombre de reprises. 

La m√©thode de l'histogramme permet de contourner ces obstacles. L'id√©e de discr√©tiser chaque variable en associant chaque observation √† un groupe, bas√© par exemple sur le quantile. En utilisant un entier entre 0 et 255 comme identifiant de ces groupes, la matrice de donn√©es est encod√©e dans un format UInt8, lequel accapare 8 fois moins de m√©moire qu'un format Float64 (un _numeric_ en R). 

Avant la construction des arbres, la librairie EvoTrees effectue cette discr√©tisation en trouvant d'abord les quantiles pour chacune des variables (get_edges), puis en cr√©ant une matrice de `UInt8`.

```julia
edges = EvoTrees.get_edges(X_train, params.nbins)
X_bin = EvoTrees.binarize(X_train, edges)
```

En choisissant le nombre de groupe (nbins) comme √©tant 16, le probl√®me √† r√©soudre prend la forme suivante d'un point de vue univari√©.

![](bin_one_ways.png)

Sous cette formulation, le nombre de conditions √† √©valuer se limite d√©sormais √† 15 (ou plus g√©n√©ralement, nbins-1). 

Il reste enfin √† d√©finir le gain associ√© √† chacun des bris. Une force du gradient boosting est sa flexibilit√©. Sous l'implantation introduite par Xgboost, il suffit de d√©finir une fonction de perte qui soit convexe et donc que la d√©riv√©e seconde existe et soit positive en tout point. Pour l'illustrer, on peut prendre le cas d'une r√©gression classique. 

Avec une r√©gression des moindre carr√©s, la perte est d√©finie par $(y - pred)^2$. Cette perte a une forme parabolique et son minimum est bien entendu lorsque la valeur pr√©dite √©gale la valeur observ√©e. La notion critique √† remarquer est qu'en ne connaissant que les d√©riv√©es premi√®res et secondes de la perte par rapport √† la pr√©diction, il est possible de d√©terminer non seulement quel serait la pr√©diction optimale, mais √©galement la r√©duction de la perte. 

Pour la premi√®re des 15 conditions possibles, l'arbre distinguerait les donn√©es en deux groupes (gauche et droite) de la mani√®re suivante:  

![](first_split.png)

Le gain se d√©finit comme la r√©duction de la perte qu'apporterait une modification √† la pr√©diction. Il est calcul√© s√©par√©ment pour les groupes de gauche et de droite. La perte associ√©e √† diff√©rentes pr√©dictions pour le groupe de gauche est la suivante:

![](left_parabole.png)

On calcule √©galement la perte sur l'ensemble des donn√©es. Effectuer un bris dans l'arbre devra apporter un gain par rapport √† cette valeur de r√©f√©rence. 

Il est √† noter que la perte minimale est atteinte lorsque la pr√©diction est de -1.11, ce qui correspond √† la moyenne des r√©sidus pour le groupe 1. 

Puisqu'une approximation de second degr√© (i.e. les d√©riv√©es premi√®res et secondes) est utilis√©e pour repr√©senter la perte, il existe une solution analytique permettant d'obtenir la valeur de la pr√©diction optimale et de la r√©duction de la perte associ√©e √† cette derni√®re. √áa revient √† trouver le minimum d'une fonction parabolique, soit la valeur de la pr√©diction o√π la d√©riv√©e premi√®re de la perte est √©gale √† 0. La d√©riv√©e de la fonction de perte √©tant lin√©aire, l'approche par descente du gradient donne une solution exacte. 

$gain = (Œ¥) ^ 2 / (‚àëŒ¥¬≤ + Œª * ‚àëùë§)/2$

$pred = - Œ∑ * ‚àëŒ¥ / (‚àëŒ¥¬≤ + Œª * ‚àëùë§)$
