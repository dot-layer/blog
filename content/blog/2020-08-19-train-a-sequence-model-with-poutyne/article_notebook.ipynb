{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Installation and import of all required package."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade poutyne\n",
    "%pip install --upgrade colorama\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from poutyne import set_seeds\n",
    "from poutyne.framework import Experiment\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The LSTM network.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dimension = 300\n",
    "num_layer = 1\n",
    "bidirectional = False\n",
    "\n",
    "lstm_network = nn.LSTM(input_size=dimension,\n",
    "                       hidden_size=dimension,\n",
    "                       num_layers=num_layer,\n",
    "                       bidirectional=bidirectional,\n",
    "                       batch_first=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The fully connected network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dim = dimension #the output of the LSTM\n",
    "tag_dimension = 8\n",
    "\n",
    "fully_connected_network = nn.Linear(input_dim, tag_dimension)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training constant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.1\n",
    "\n",
    "epoch_number = 10\n",
    "\n",
    "set_seeds(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset download"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def download_data(saving_dir, data_type):\n",
    "    \"\"\"\n",
    "    Function to download the dataset using data_type to specify if we want the train, valid or test.\n",
    "    \"\"\"\n",
    "\n",
    "    # hardcoded url to download the pickled dataset\n",
    "    root_url = \"https://dot-layer.github.io/blog-external-assets/train_rnn/{}.p\"\n",
    "\n",
    "    url = root_url.format(data_type)\n",
    "    r = requests.get(url)\n",
    "    os.makedirs(saving_dir, exist_ok=True)\n",
    "\n",
    "    open(os.path.join(saving_dir, f\"{data_type}.p\"), 'wb').write(r.content)\n",
    "\n",
    "download_data('./data/', \"train\")\n",
    "download_data('./data/', \"valid\")\n",
    "download_data('./data/', \"test\")\n",
    "\n",
    "train_data = pickle.load(open(\"./data/train.p\", \"rb\"))  # 728,789 examples\n",
    "valid_data = pickle.load(open(\"./data/valid.p\", \"rb\"))  # 182,198 examples\n",
    "test_data = pickle.load(open(\"./data/test.p\", \"rb\"))  # 100,000 examples\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[0:2]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vectorization of the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class EmbeddingVectorizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Embedding vectorizer\n",
    "        \"\"\"\n",
    "        fasttext.util.download_model('fr', if_exists='ignore')\n",
    "        self.embedding_model = fasttext.load_model(\"./cc.fr.300.bin\")\n",
    "\n",
    "    def __call__(self, address):\n",
    "        \"\"\"\n",
    "        Convert address to embedding vectors\n",
    "        :param address: The address to convert\n",
    "        :return: The embeddings vectors\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for word in address.split():\n",
    "            embeddings.append(self.embedding_model[word])\n",
    "        return embeddings\n",
    "\n",
    "embedding_vectorizer = EmbeddingVectorizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data complete vectorizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DatasetVectorizer:\n",
    "    def __init__(self, embedding_vectorizer):\n",
    "        self.embedding_vectorizer = embedding_vectorizer\n",
    "        self.tags_set = {\n",
    "            \"StreetNumber\": 0,\n",
    "            \"StreetName\": 1,\n",
    "            \"Unit\": 2,\n",
    "            \"Municipality\": 3,\n",
    "            \"Province\": 4,\n",
    "            \"PostalCode\": 5,\n",
    "            \"Orientation\": 6,\n",
    "            \"GeneralDelivery\": 7\n",
    "        }\n",
    "\n",
    "    def vectorize(self, data):  # We vectorize inplace\n",
    "        for idx, item in enumerate(data):\n",
    "            data[idx] = self._item_vectorizing(item)\n",
    "\n",
    "    def _item_vectorizing(self, item):\n",
    "        address = item[0]\n",
    "        address_vector = self.embedding_vectorizer(address)\n",
    "\n",
    "        tags = item[1]\n",
    "        idx_tags = self._convert_tags_to_idx(tags)\n",
    "\n",
    "        return address_vector, idx_tags\n",
    "\n",
    "    def _convert_tags_to_idx(self, tags):\n",
    "        idx_tags = []\n",
    "        for tag in tags:\n",
    "            idx_tags.append(self.tags_set[tag])\n",
    "        return idx_tags\n",
    "\n",
    "dataset_vectorizer = DatasetVectorizer(embedding_vectorizer)\n",
    "\n",
    "dataset_vectorizer.vectorize(train_data)\n",
    "dataset_vectorizer.vectorize(valid_data)\n",
    "dataset_vectorizer.vectorize(test_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataloader and pad collate function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def pad_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    The collate_fn that can add padding to the sequences so all can have\n",
    "    the same length as the longest one.\n",
    "\n",
    "    Args:\n",
    "        batch (List[List, List]): The batch data, where the first element\n",
    "        of the tuple is the word idx and the second element are the target\n",
    "        label.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (x, y). The element x is a tuple containing (1) a tensor of padded\n",
    "        word vectors and (2) their respective lengths of the sequences. The element\n",
    "        y is a tensor of padded tag indices. The word vectors are padded with vectors\n",
    "        of 0s and the tag indices are padded with -100s. Padding with -100 is done\n",
    "        because of the cross-entropy loss, the accuracy metric and the F1 metric ignores\n",
    "        the targets with values -100.\n",
    "    \"\"\"\n",
    "\n",
    "    # This gets us two lists of tensors and a list of integer.\n",
    "    # Each tensor in the first list is a sequence of word vectors.\n",
    "    # Each tensor in the second list is a sequence of tag indices.\n",
    "    # The list of integer consist of the lengths of the sequences in order.\n",
    "    sequences_vectors, sequences_labels, lengths = zip(*[\n",
    "        (torch.FloatTensor(seq_vectors), torch.LongTensor(labels), len(seq_vectors))\n",
    "         for (seq_vectors, labels) in sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "    ])\n",
    "\n",
    "    lengths = torch.LongTensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=0)\n",
    "\n",
    "    padded_sequences_labels = pad_sequence(sequences_labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return (padded_sequences_vectors, lengths), padded_sequences_labels\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, collate_fn=pad_collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=pad_collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The complete network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FullNetWork(nn.Module):\n",
    "    def __init__(self, lstm_network, fully_connected_network):\n",
    "        super().__init__()\n",
    "        self.hidden_state = None\n",
    "\n",
    "        self.lstm_network = lstm_network\n",
    "        self.fully_connected_network = fully_connected_network\n",
    "\n",
    "    def forward(self, padded_sequences_vectors, lengths):\n",
    "        \"\"\"\n",
    "            Defines the computation performed at every call.\n",
    "        \"\"\"\n",
    "        total_length = padded_sequences_vectors.shape[1]\n",
    "        pack_padded_sequences_vectors = pack_padded_sequence(padded_sequences_vectors, lengths, batch_first=True)\n",
    "\n",
    "        lstm_out, self.hidden_state = self.lstm_network(pack_padded_sequences_vectors)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True, total_length=total_length)\n",
    "\n",
    "        tag_space = self.fully_connected_network(lstm_out)\n",
    "        return tag_space.transpose(-1, 1) # we need to transpose since it's a sequence\n",
    "\n",
    "full_network = FullNetWork(lstm_network, fully_connected_network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimizer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = optim.SGD(full_network.parameters(), lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Poutyne experiment and the training loop."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "exp = Experiment(\"./\", full_network, device=cuda_device, optimizer=optimizer,\n",
    "                 loss_function=cross_entropy, batch_metrics=[\"acc\"])\n",
    "\n",
    "\n",
    "exp.train(train_loader, valid_generator=valid_loader, epochs=epoch_number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **bigger** model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dimension = 300\n",
    "num_layer = 2\n",
    "bidirectional = True\n",
    "\n",
    "lstm_network = nn.LSTM(input_size=dimension,\n",
    "                       hidden_size=dimension,\n",
    "                       num_layers=num_layer,\n",
    "                       bidirectional=bidirectional,\n",
    "                       batch_first=True)\n",
    "\n",
    "input_dim = dimension * 2 #since bidirectional\n",
    "\n",
    "fully_connected_network = nn.Linear(input_dim, tag_dimension)\n",
    "\n",
    "full_network_bi_lstm = FullNetWork(lstm_network, fully_connected_network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bigger model training loop."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "exp_bi_lstm = Experiment(\"./\", full_network_bi_lstm, device=cuda_device, optimizer=optimizer,\n",
    "                 loss_function=cross_entropy, batch_metrics=[\"acc\"])\n",
    "exp_bi_lstm.train(train_loader, valid_generator=valid_loader, epochs=epoch_number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The test phase."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "exp.test(test_loader)\n",
    "exp_bi_lstm.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The zero shot evaluation datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "download_data('./data/', \"us\")\n",
    "download_data('./data/', \"gb\")\n",
    "download_data('./data/', \"ru\")\n",
    "download_data('./data/', \"mx\")\n",
    "\n",
    "us_data = pickle.load(open(\"./data/us.p\", \"rb\"))  # 100,000 examples\n",
    "gb_data = pickle.load(open(\"./data/gb.p\", \"rb\"))  # 100,000 examples\n",
    "ru_data = pickle.load(open(\"./data/ru.p\", \"rb\"))  # 100,000 examples\n",
    "mx_data = pickle.load(open(\"./data/mx.p\", \"rb\"))  # 100,000 examples\n",
    "\n",
    "dataset_vectorizer.vectorize(us_data)\n",
    "dataset_vectorizer.vectorize(gb_data)\n",
    "dataset_vectorizer.vectorize(ru_data)\n",
    "dataset_vectorizer.vectorize(mx_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eval on US and UK datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "us_loader = DataLoader(us_data, batch_size=batch_size, collate_fn=pad_collate_fn)\n",
    "exp.test(us_loader)\n",
    "exp_bi_lstm.test(us_loader)\n",
    "\n",
    "gb_loader = DataLoader(gb_data, batch_size=batch_size, collate_fn=pad_collate_fn)\n",
    "exp.test(gb_loader)\n",
    "exp_bi_lstm.test(gb_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eval on RU and MX."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ru_loader = DataLoader(ru_data, batch_size=batch_size, collate_fn=pad_collate_fn)\n",
    "exp.test(ru_loader)\n",
    "exp_bi_lstm.test(ru_loader)\n",
    "\n",
    "mx_loader = DataLoader(mx_data, batch_size=batch_size, collate_fn=pad_collate_fn)\n",
    "exp.test(mx_loader)\n",
    "exp_bi_lstm.test(mx_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}